{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re\n",
    "import os\n",
    "from itertools import groupby\n",
    "import datetime as dt\n",
    "\n",
    "#visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('poster', rc={'font.size':35,\n",
    "                              'axes.titlesize':50,\n",
    "                              'axes.labelsize':35})\n",
    "\n",
    "pd.set_option('display.max_rows', 100000)\n",
    "pd.set_option('display.max_columns', 50000)\n",
    "pd.set_option('display.width', 100000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Definitions\n",
    "\n",
    "- A   = active lever (1 = Left, any other number = Right)\n",
    "- B   = number of right nose pokes\n",
    "- C   = number of left nose pokes\n",
    "#### D   = event time stamp\n",
    "#### E   = event identity stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Stamps\n",
    "\n",
    "####      46 - Right lever extends \n",
    "- trial starts\n",
    "\n",
    "####      47 - Left lever extends\n",
    "- trial starts\n",
    "\n",
    "####      12 - Intertrial interval begins\n",
    "####      13 - Intertrial interval over and reinforcement available again\n",
    "\n",
    "####      10 - ITI Right lever press\n",
    "####      11 - ITI Left lever press\n",
    "####      14 - ITI Head entry\n",
    "\n",
    "####      40 - PR reset lever pressed (right)\n",
    "####      41 - PR reset lever pressed (left)\n",
    "####      3  - Non-ITI Left lever press\n",
    "####       4  - Non-ITI Right lever press\n",
    "####      7  - Non-ITI Head entry\n",
    "####      17 - Pellet delivery\n",
    "\n",
    "-      5  - Reinforced left lever press\n",
    "-      6  - Reinforced right lever press\n",
    "-      8  - Non-ITI Right nose poke\n",
    "-      9  - Non-ITI Left nose poke\n",
    "-      15 - ITI Right nose-poke\n",
    "-      16 - ITI Left nose-poke\n",
    "-      18 - Tone delivery\n",
    "-      42 - Right cue light active\n",
    "-      43 - Left cue light active\n",
    "-      44 - Right cue light off\n",
    "-      45 - Left cue light off\n",
    "-      48 - Right lever retracts\n",
    "-      49 - Left lever retracts\n",
    "-      50 - Head entry to initiate trial\n",
    "-     100 - End of session marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info_common(file_path_name):\n",
    "    # takes in a file path, finds the date, animal_number, session, session number, and sub_session, saves each accordingly\n",
    "    import re\n",
    "    \n",
    "    task = file_path_name.split('/')[-1].split('_')[0]\n",
    "    session = int(file_path_name.split('/')[-1].split('_')[1])\n",
    "    animal = int(file_path_name.split('/')[-1].split('_')[2])\n",
    "    date = file_path_name.split('/')[-1].split('_')[3]\n",
    "\n",
    "    return task, session, animal, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_array_from_path(file_path_name):\n",
    "    # takes in file path, creates array (each row of array is a row from original med file)\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    data = pd.read_table(file_path_name)\n",
    "    data_table = pd.DataFrame(data = data)\n",
    "    data_array = data_table.values\n",
    "    \n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_and_times(array, event_letter, time_letter):\n",
    "    #takes in array and the letters Med PC program uses to signify an event_stamp and time_stamp; \n",
    "    #finds all event_stamps and corresponding time_stamps; creats pandas dataframe\n",
    "    import re\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    i = 0\n",
    "    event_data = []\n",
    "    time_data = []\n",
    "    while i < len(array):\n",
    "        if re.search(event_letter, str(array[i])):\n",
    "            i = i + 1\n",
    "            while re.search('\\[\\'\\ \\ ', str(array[i])):\n",
    "                split = array[i][0].split()[1:]\n",
    "                for element in split:\n",
    "                    event_data.append(float(element))\n",
    "                i = i + 1\n",
    "        elif re.search(time_letter, str(array[i])):\n",
    "            i = i + 1\n",
    "            while re.search('\\[\\'\\ \\ ', str(array[i])):\n",
    "                split = array[i][0].split()[1:]\n",
    "                for element in split:\n",
    "                    time_data.append(float(element))\n",
    "                i = i + 1\n",
    "        else:\n",
    "            i = i + 1\n",
    "    \n",
    "    eandt = np.column_stack((event_data, time_data))\n",
    "    es_et = pd.DataFrame(data = eandt)\n",
    "    es_et.columns = ['event_stamp', 'time_stamp']\n",
    "    \n",
    "    return es_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_times_LPD(events_and_times, right_extends, left_extends, ITI_start, ITI_end, session_end):\n",
    "    #takes in dataframe of events and corresponding time_stamps and the Med PC program code for start and end of trial segment\n",
    "    #e.g. conditioned stimulus onset and offset, ITI onset and offset - here both levers extend so can just use right lever as start\n",
    "    #finds time_stamps for each start and end, puts into new dataframe\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    start_time = events_and_times[(events_and_times.event_stamp == right_extends)]['time_stamp'].values\n",
    "    end_time = events_and_times[(events_and_times.event_stamp == ITI_start) | (events_and_times.event_stamp == session_end)]['time_stamp'].values\n",
    "    start_time_ITI = events_and_times[events_and_times.event_stamp == ITI_start]['time_stamp'].values\n",
    "    end_time_ITI = events_and_times[events_and_times.event_stamp == ITI_end]['time_stamp'].values\n",
    "    \n",
    "    times = pd.DataFrame(data = [start_time, end_time, start_time_ITI, end_time_ITI])\n",
    "    times = times.T\n",
    "    times.columns = ['trial_start', 'trial_end', 'ITI_start', 'ITI_end']\n",
    "    \n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trial_df(events_and_times, trial_times, trial_type):\n",
    "    #takes in df of events and times and df of trial times\n",
    "    #creates tidy df containing events and times according to trials\n",
    "    i = 0\n",
    "    trial_data = pd.DataFrame()\n",
    "    \n",
    "    if trial_type == 'ITI':\n",
    "        while i < len(trial_times):\n",
    "            data = events_and_times[(events_and_times['time_stamp'] >= trial_times['ITI_start'][i]) & (events_and_times['time_stamp'] <= trial_times['ITI_end'][i])]\n",
    "            data['trial_#'] = [i]*len(data)\n",
    "            data['ITI_start'] = trial_times['ITI_start'][i]\n",
    "            data['ITI_end'] = trial_times['ITI_end'][i]\n",
    "            trial_data = pd.concat([trial_data, data], axis = 0, ignore_index=True)\n",
    "            i = i + 1\n",
    "    elif trial_type == 'within':\n",
    "        while i < len(trial_times):\n",
    "            data = events_and_times[(events_and_times['time_stamp'] >= trial_times['trial_start'][i]) & (events_and_times['time_stamp'] <= trial_times['trial_end'][i])]\n",
    "            data['trial_#'] = [i]*len(data)\n",
    "            data['trial_start'] = trial_times['trial_start'][i]\n",
    "            data['trial_end'] = trial_times['trial_end'][i]\n",
    "            trial_data = pd.concat([trial_data, data], axis = 0, ignore_index=True)\n",
    "            i = i + 1\n",
    "    \n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(trial_data, event_num):\n",
    "    #get count of event_num\n",
    "    trials = len((trial_data['trial_#'].unique()))\n",
    "    i = 0\n",
    "    count = []\n",
    "    while i < trials:\n",
    "        data = trial_data[trial_data['trial_#'] == i]\n",
    "        count.append(len(data[data['event_stamp'] == event_num]))\n",
    "        i = i + 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latency(trial_data, event_num, trial_type):\n",
    "    #get latency of time between trial_start and event_num\n",
    "    trials = len((trial_data['trial_#'].unique()))\n",
    "    i = 0\n",
    "    latency_1st = []\n",
    "    latency_ave = []\n",
    "    while i < trials:\n",
    "        data = trial_data[trial_data['trial_#'] == i]\n",
    "        data = data[data['event_stamp'] == event_num]\n",
    "        if len(data) < 1:\n",
    "            latency_1st.append(np.nan)\n",
    "            latency_ave.append(np.nan)\n",
    "        else:\n",
    "            if trial_type == 'ITI':\n",
    "                latency_1st.append((data['time_stamp'] - data['ITI_start']).values[0]/100)\n",
    "                latency_ave.append((data['time_stamp'] - data['ITI_start']).values.mean()/100)\n",
    "            elif trial_type == 'within':\n",
    "                latency_1st.append((data['time_stamp'] - data['trial_start']).values[0]/100)\n",
    "                latency_ave.append((data['time_stamp'] - data['trial_start']).values.mean()/100)\n",
    "        i = i + 1\n",
    "    \n",
    "    return latency_1st, latency_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_df(trial_data, event_dic, trial_type):\n",
    "    \n",
    "    trials = len((trial_data['trial_#'].unique()))\n",
    "    \n",
    "    #get times\n",
    "    if trial_type == 'ITI':\n",
    "        times_df = pd.DataFrame(data = [trial_data.groupby('trial_#')['ITI_start'].unique(), trial_data.groupby('trial_#')['ITI_end'].unique()])\n",
    "        times_df = times_df.T\n",
    "    elif trial_type == 'within':\n",
    "        times_df = pd.DataFrame(data = [trial_data.groupby('trial_#')['trial_start'].unique(), trial_data.groupby('trial_#')['trial_end'].unique()])\n",
    "        times_df = times_df.T  \n",
    "        \n",
    "    i = 0\n",
    "    trial_times = []\n",
    "\n",
    "    while i < times_df.shape[0]:\n",
    "        if trial_type == 'ITI':\n",
    "            trial_time = (times_df.iloc[i]['ITI_end'] - times_df.iloc[i]['ITI_start'])/100\n",
    "        elif trial_type == 'within':\n",
    "            trial_time = (times_df.iloc[i]['trial_end'] - times_df.iloc[i]['trial_start'])/100\n",
    "        trial_times.append(trial_time[0])\n",
    "        i += 1\n",
    "    \n",
    "    session_data = pd.DataFrame(index=np.arange(0,trials))\n",
    "\n",
    "    for name, event in event_dic.items():\n",
    "        session_data[str(name + '_count')] = count(trial_data, event)\n",
    "        session_data[str(name + '_latency_1st')], session_data[str(name + '_latency_ave')] = latency(trial_data, event, trial_type)\n",
    "    \n",
    "    #add bin cout (6 bins of 10 min each)\n",
    "    if trial_type == 'ITI':\n",
    "        session_data['trial_bin'] = pd.cut(times_df['ITI_end'].str[0].values/100, bins=6, labels=False)\n",
    "    elif trial_type == 'within':\n",
    "        session_data['trial_bin'] = pd.cut(times_df['trial_end'].str[0].values/100, bins=6, labels=False)\n",
    "    \n",
    "    session_data['trial_num'] = np.arange(session_data.shape[0])\n",
    "    session_data['trial_duration'] = trial_times\n",
    "    \n",
    "    return session_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in animal meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal</th>\n",
       "      <th>cage</th>\n",
       "      <th>group</th>\n",
       "      <th>lever</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1215</td>\n",
       "      <td>SA319</td>\n",
       "      <td>4</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1216</td>\n",
       "      <td>SA319</td>\n",
       "      <td>4</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1217</td>\n",
       "      <td>SA319</td>\n",
       "      <td>4</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1236</td>\n",
       "      <td>SA326</td>\n",
       "      <td>5</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1237</td>\n",
       "      <td>SA326</td>\n",
       "      <td>5</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   animal   cage  group  lever\n",
       "0    1215  SA319      4  right\n",
       "1    1216  SA319      4  right\n",
       "2    1217  SA319      4  right\n",
       "3    1236  SA326      5  right\n",
       "4    1237  SA326      5  right"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read animal info (lever assignment, group etc) into df\n",
    "\n",
    "path_animal_info = '/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/assignments/2021April_meta.xlsx'\n",
    "    \n",
    "animal_info = pd.read_excel(path_animal_info)\n",
    "animal_info = pd.DataFrame(data = animal_info)\n",
    "\n",
    "animal_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1230_210331'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever'\n",
    "\n",
    "file_names = os.listdir(path)\n",
    "print(len(file_names))\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "for file in file_names:\n",
    "    \n",
    "    file_path = path + '/' + file\n",
    "    file_paths.append(file_path)\n",
    "\n",
    "print(len(file_paths))\n",
    "file_paths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1230_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1219_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1230_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1232_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1249_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1218_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1232_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1224_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1229_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1218_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1231_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1220_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1228_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1225_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1226_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1243_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1243_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1230_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1219_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1231_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1230_190321\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1224_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1226_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1218_190321\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1243_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1225_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1248_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1249_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1244_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1218_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1231_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1219_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1229_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1228_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1227_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1232_190321\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1242_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1243_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1232_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/.DS_Store\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1250_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1225_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1250_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1248_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1228_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1249_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1242_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1227_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1244_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1226_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1229_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1224_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1218_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1232_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1218_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1243_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1232_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1243_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1249_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1244_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1250_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1224_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1227_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1226_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1242_210408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1228_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1230_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1248_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1230_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1243_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1225_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1226_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1250_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1229_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1231_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1242_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1232_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1230_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1249_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1218_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1228_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1219_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1229_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1225_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1224_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1249_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1232_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1231_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1249_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1225_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1230_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1243_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1229_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1226_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1226_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1224_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1218_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1228_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1219_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1224_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1228_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1224_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1248_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1224_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1232_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1242_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1230_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1243_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1227_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1228_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1244_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1228_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1250_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1218_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1249_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1226_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1249_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1226_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1230_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1248_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1232_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1250_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1228_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1224_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1227_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1242_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1243_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1244_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1231_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1244_210405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1219_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1227_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1226_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1218_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1249_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1248_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1224_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1249_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1242_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1244_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1227_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1219_190321\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1225_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1229_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1250_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1226_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1218_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1228_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1219_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1230_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1248_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1230_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1231_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1218_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1231_190321\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1250_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1225_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1228_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1250_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1248_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1219_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1242_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1242_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1244_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1229_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1224_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1227_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1219_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1230_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1231_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1218_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1231_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1225_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1226_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1232_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1248_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1231_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1231_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1244_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1249_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1227_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1229_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1243_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1242_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1250_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1219_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1219_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1250_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1242_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1248_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1232_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1229_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1224_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1249_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1225_210409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1227_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1228_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1244_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1226_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1243_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1242_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1243_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1250_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1232_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1229_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1219_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1225_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1229_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1225_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1218_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1248_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1224_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1248_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1230_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1250_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1227_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1227_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1244_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1228_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1242_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1231_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1244_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1218_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1228_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1229_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1219_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1225_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1224_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1224_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1227_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1244_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1232_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1242_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1231_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1248_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1243_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1250_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1230_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1228_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1227_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1226_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1244_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1218_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_8_1249_210405\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R3_1_1248_210402\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1219_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1232_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1250_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1229_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1249_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_4_1231_210409\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_7_1230_210326\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR3_1_1242_210403\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_6_1243_210322\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_5_1225_210319\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_4_1226_210318\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1227_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1219_210317\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1248_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1244_210331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1227_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDFR3R1_1_1248_210331\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDPRR1_1_1244_210401\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1243_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1250_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1225_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1225_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1249_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_1_1229_210315\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_2_1229_210407\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_1_1242_210406\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPDE_3_1226_210408\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_2_1232_210316\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Behavior/med_boxes/reward_learning_tc/round2/orig_lever/LPD_3_1231_210317\n",
      "CPU times: user 3min 56s, sys: 5.86 s, total: 4min 2s\n",
      "Wall time: 4min 4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>session</th>\n",
       "      <th>cage</th>\n",
       "      <th>animal</th>\n",
       "      <th>group</th>\n",
       "      <th>active_lever</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>trial_bin</th>\n",
       "      <th>trial_duration</th>\n",
       "      <th>reinforcement_count</th>\n",
       "      <th>reinforcement_latency_1st</th>\n",
       "      <th>HE_count</th>\n",
       "      <th>HE_latency_1st</th>\n",
       "      <th>HE_latency_ave</th>\n",
       "      <th>right_lever_count</th>\n",
       "      <th>right_lever_latency_1st</th>\n",
       "      <th>left_lever_count</th>\n",
       "      <th>left_lever_latency_1st</th>\n",
       "      <th>reinforcement_latency_ave</th>\n",
       "      <th>right_lever_latency_ave</th>\n",
       "      <th>left_lever_latency_ave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24036</th>\n",
       "      <td>LPD</td>\n",
       "      <td>ITI</td>\n",
       "      <td>210317</td>\n",
       "      <td>3</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1231</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>59.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24037</th>\n",
       "      <td>LPD</td>\n",
       "      <td>ITI</td>\n",
       "      <td>210317</td>\n",
       "      <td>3</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1231</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>89.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2.21</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24038</th>\n",
       "      <td>LPD</td>\n",
       "      <td>ITI</td>\n",
       "      <td>210317</td>\n",
       "      <td>3</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1231</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>29.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24039</th>\n",
       "      <td>LPD</td>\n",
       "      <td>ITI</td>\n",
       "      <td>210317</td>\n",
       "      <td>3</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1231</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>59.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24040</th>\n",
       "      <td>LPD</td>\n",
       "      <td>ITI</td>\n",
       "      <td>210317</td>\n",
       "      <td>3</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1231</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>53</td>\n",
       "      <td>5</td>\n",
       "      <td>89.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      task part    date  session   cage  animal  group active_lever  trial_num  trial_bin  trial_duration  reinforcement_count  reinforcement_latency_1st  HE_count  HE_latency_1st  HE_latency_ave  right_lever_count  right_lever_latency_1st  left_lever_count  left_lever_latency_1st  reinforcement_latency_ave  right_lever_latency_ave  left_lever_latency_ave\n",
       "24036  LPD  ITI  210317        3  SA324    1231      4         left         49          5           59.99                    1                        0.0         1            1.15            1.15                  0                      NaN                 0                     NaN                        0.0                      NaN                     NaN\n",
       "24037  LPD  ITI  210317        3  SA324    1231      4         left         50          5           89.99                    1                        0.0         1            2.21            2.21                  0                      NaN                 1                    0.06                        0.0                      NaN                    0.06\n",
       "24038  LPD  ITI  210317        3  SA324    1231      4         left         51          5           29.99                    1                        0.0         1            1.04            1.04                  0                      NaN                 0                     NaN                        0.0                      NaN                     NaN\n",
       "24039  LPD  ITI  210317        3  SA324    1231      4         left         52          5           59.99                    1                        0.0         1            1.15            1.15                  0                      NaN                 1                    0.06                        0.0                      NaN                    0.06\n",
       "24040  LPD  ITI  210317        3  SA324    1231      4         left         53          5           89.99                    1                        0.0         1            1.02            1.02                  0                      NaN                 0                     NaN                        0.0                      NaN                     NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "final_data = pd.DataFrame()\n",
    "\n",
    "bit_dic = {'reinforcement': 17, 'right_lever': 4, 'left_lever': 3, 'HE': 7}\n",
    "ITI_dic = {'reinforcement': 17, 'right_lever': 10, 'left_lever': 11, 'HE': 14}\n",
    "\n",
    "for file in file_paths:\n",
    "\n",
    "    print(file) \n",
    "    \n",
    "    if file.split('/')[-1] == '.DS_Store':\n",
    "        continue\n",
    "    \n",
    "    #proccess file\n",
    "    task, session, animal, date = get_file_info_common(file)\n",
    "    array = make_array_from_path(file)\n",
    "    events_and_times = get_events_and_times(array, \"E\", \"D\")\n",
    "    trial_times = get_trial_times_LPD(events_and_times, 46, 47, 12, 13, 100)\n",
    "    trial_data = create_trial_df(events_and_times, trial_times, 'within')\n",
    "    ITItrial_data = create_trial_df(events_and_times, trial_times, 'ITI')\n",
    "    session_data = create_session_df(trial_data, bit_dic, 'within')\n",
    "    ITIsession_data = create_session_df(ITItrial_data, ITI_dic, 'ITI')\n",
    "    \n",
    "    #get animal metadata\n",
    "    active_lever = animal_info[animal_info['animal'] == int(animal)]['lever'].iloc[0]\n",
    "    group = int(animal_info[animal_info['animal'] == int(animal)]['group'])\n",
    "    cage = animal_info[animal_info['animal'] == int(animal)]['cage'].iloc[0]\n",
    "    \n",
    "    #create pandas tidy df for within session\n",
    "    session_data['task'] = [task]*(session_data.shape[0])\n",
    "    session_data['part'] = ['within']*(session_data.shape[0]) \n",
    "    session_data['date'] = [date]*(session_data.shape[0])\n",
    "    session_data['animal'] = [animal]*(session_data.shape[0])\n",
    "    session_data['session'] = [session]*(session_data.shape[0])\n",
    "    session_data['active_lever'] = [active_lever]*(session_data.shape[0])\n",
    "    session_data['group'] = [group]*(session_data.shape[0])\n",
    "    session_data['cage'] = [cage]*(session_data.shape[0])\n",
    "    \n",
    "    session_data = session_data[['task', 'part', 'date', 'session', 'cage', 'animal', 'group', 'active_lever', \n",
    "                                 'trial_num', 'trial_bin', 'trial_duration', 'reinforcement_count', 'reinforcement_latency_1st', \n",
    "                                 'HE_count', 'HE_latency_1st', 'HE_latency_ave',\n",
    "                                 'right_lever_count', 'right_lever_latency_1st',\n",
    "                                 'left_lever_count', 'left_lever_latency_1st',\n",
    "                                 'reinforcement_latency_ave', 'right_lever_latency_ave', 'left_lever_latency_ave']]\n",
    "    \n",
    "    #create pandas tidy df for within ITI\n",
    "    ITIsession_data['task'] = [task]*(ITIsession_data.shape[0]) \n",
    "    ITIsession_data['part'] = ['ITI']*(ITIsession_data.shape[0]) \n",
    "    ITIsession_data['date'] = [date]*(ITIsession_data.shape[0])\n",
    "    ITIsession_data['animal'] = [animal]*(ITIsession_data.shape[0])\n",
    "    ITIsession_data['session'] = [session]*(ITIsession_data.shape[0])\n",
    "    ITIsession_data['active_lever'] = [active_lever]*(ITIsession_data.shape[0])\n",
    "    ITIsession_data['group'] = [group]*(ITIsession_data.shape[0])\n",
    "    ITIsession_data['cage'] = [cage]*(ITIsession_data.shape[0])\n",
    "    \n",
    "    ITIsession_data = ITIsession_data[['task', 'part', 'date', 'session', 'cage', 'animal', 'group', 'active_lever', \n",
    "                                 'trial_num', 'trial_bin', 'trial_duration', 'reinforcement_count', 'reinforcement_latency_1st', \n",
    "                                 'HE_count', 'HE_latency_1st', 'HE_latency_ave',\n",
    "                                 'right_lever_count', 'right_lever_latency_1st',\n",
    "                                 'left_lever_count', 'left_lever_latency_1st',\n",
    "                                 'reinforcement_latency_ave', 'right_lever_latency_ave', 'left_lever_latency_ave']]\n",
    "\n",
    "    #add to final data frame\n",
    "    data_int = pd.concat([session_data, ITIsession_data], axis = 0, ignore_index=True)\n",
    "    if final_data.shape[0] == 0:\n",
    "        final_data = data_int\n",
    "    else:\n",
    "        final_data = pd.concat([final_data, data_int], axis = 0, ignore_index=True)\n",
    "\n",
    "final_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24041, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>part</th>\n",
       "      <th>date</th>\n",
       "      <th>session</th>\n",
       "      <th>cage</th>\n",
       "      <th>animal</th>\n",
       "      <th>group</th>\n",
       "      <th>active_lever</th>\n",
       "      <th>trial_num</th>\n",
       "      <th>trial_bin</th>\n",
       "      <th>trial_duration</th>\n",
       "      <th>reinforcement_count</th>\n",
       "      <th>reinforcement_latency_1st</th>\n",
       "      <th>HE_count</th>\n",
       "      <th>HE_latency_1st</th>\n",
       "      <th>HE_latency_ave</th>\n",
       "      <th>active_lever_count</th>\n",
       "      <th>active_lever_latency_1st</th>\n",
       "      <th>inactive_lever_count</th>\n",
       "      <th>inactive_lever_latency_1st</th>\n",
       "      <th>active_lever_latency_ave</th>\n",
       "      <th>inactive_lever_latency_ave</th>\n",
       "      <th>reinforcement_latency_ave</th>\n",
       "      <th>lever_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LPDFR3R1</td>\n",
       "      <td>within</td>\n",
       "      <td>210331</td>\n",
       "      <td>1</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1230</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.73</td>\n",
       "      <td>1</td>\n",
       "      <td>6.73</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.73</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LPDFR3R1</td>\n",
       "      <td>within</td>\n",
       "      <td>210331</td>\n",
       "      <td>1</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1230</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1</td>\n",
       "      <td>3.73</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.203333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LPDFR3R1</td>\n",
       "      <td>within</td>\n",
       "      <td>210331</td>\n",
       "      <td>1</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1230</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1</td>\n",
       "      <td>4.37</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LPDFR3R1</td>\n",
       "      <td>within</td>\n",
       "      <td>210331</td>\n",
       "      <td>1</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1230</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6.18</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.636667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.18</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LPDFR3R1</td>\n",
       "      <td>within</td>\n",
       "      <td>210331</td>\n",
       "      <td>1</td>\n",
       "      <td>SA324</td>\n",
       "      <td>1230</td>\n",
       "      <td>4</td>\n",
       "      <td>left</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.42</td>\n",
       "      <td>1</td>\n",
       "      <td>6.42</td>\n",
       "      <td>1</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.853333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task    part    date  session   cage  animal  group active_lever  trial_num  trial_bin  trial_duration  reinforcement_count  reinforcement_latency_1st  HE_count  HE_latency_1st  HE_latency_ave  active_lever_count  active_lever_latency_1st  inactive_lever_count  inactive_lever_latency_1st  active_lever_latency_ave  inactive_lever_latency_ave  reinforcement_latency_ave  lever_ratio\n",
       "0  LPDFR3R1  within  210331        1  SA324    1230      4         left          0          0            6.73                    1                       6.73         0             NaN             NaN                   3                      5.33                     0                         NaN                  6.020000                         NaN                       6.73          1.0\n",
       "1  LPDFR3R1  within  210331        1  SA324    1230      4         left          1          0            3.73                    1                       3.73         0             NaN             NaN                   3                      2.71                     0                         NaN                  3.203333                         NaN                       3.73          1.0\n",
       "2  LPDFR3R1  within  210331        1  SA324    1230      4         left          2          0            4.37                    1                       4.37         0             NaN             NaN                   3                      3.03                     0                         NaN                  3.800000                         NaN                       4.37          1.0\n",
       "3  LPDFR3R1  within  210331        1  SA324    1230      4         left          3          0            6.18                    1                       6.18         0             NaN             NaN                   3                      5.13                     0                         NaN                  5.636667                         NaN                       6.18          1.0\n",
       "4  LPDFR3R1  within  210331        1  SA324    1230      4         left          4          0            6.42                    1                       6.42         1            3.67            3.67                   3                      2.26                     0                         NaN                  4.853333                         NaN                       6.42          1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make new df with combined data\n",
    "df_final = final_data.copy()\n",
    "\n",
    "lp_train_df_trial = pd.DataFrame()\n",
    "\n",
    "animals = df_final['animal'].unique()\n",
    "\n",
    "for animal in animals:\n",
    "    \n",
    "    #get animal data\n",
    "    animal_data = df_final[df_final['animal'] == animal]\n",
    "    \n",
    "    #generate session df\n",
    "    sessions = animal_data['session'].unique()\n",
    "    \n",
    "    for session in sessions:\n",
    "        #get session data for animal\n",
    "        animal_data_session = animal_data[animal_data['session'] == session]\n",
    "        \n",
    "        #compute and fill session data\n",
    "        if animal_data_session['active_lever'].unique() == 'right':\n",
    "            animal_data_session['active_lever_count'] = animal_data_session['right_lever_count']\n",
    "            animal_data_session['active_lever_latency_1st'] = animal_data_session['right_lever_latency_1st']\n",
    "            animal_data_session['active_lever_latency_ave'] = animal_data_session['right_lever_latency_ave']\n",
    "            animal_data_session['inactive_lever_count'] = animal_data_session['left_lever_count']\n",
    "            animal_data_session['inactive_lever_latency_1st'] = animal_data_session['left_lever_latency_1st']\n",
    "            animal_data_session['inactive_lever_latency_ave'] = animal_data_session['left_lever_latency_ave']\n",
    "\n",
    "        elif animal_data_session['active_lever'].unique() == 'left':\n",
    "            animal_data_session['active_lever_count'] = animal_data_session['left_lever_count']\n",
    "            animal_data_session['active_lever_latency_1st'] = animal_data_session['left_lever_latency_1st']\n",
    "            animal_data_session['active_lever_latency_ave'] = animal_data_session['left_lever_latency_ave']\n",
    "            animal_data_session['inactive_lever_count'] = animal_data_session['right_lever_count']\n",
    "            animal_data_session['inactive_lever_latency_1st'] = animal_data_session['right_lever_latency_1st']\n",
    "            animal_data_session['inactive_lever_latency_ave'] = animal_data_session['right_lever_latency_ave']\n",
    "            \n",
    "        lp_train_df_trial = lp_train_df_trial.append(animal_data_session)\n",
    "        \n",
    "lp_train_df_trial.reset_index(inplace=True, drop=True)    \n",
    "\n",
    "lp_train_df_trial = lp_train_df_trial[['task', 'part', 'date', 'session', 'cage', 'animal', 'group', 'active_lever', \n",
    "                                       'trial_num', 'trial_bin', 'trial_duration',\n",
    "                                       'reinforcement_count', 'reinforcement_latency_1st',\n",
    "                                       'HE_count', 'HE_latency_1st', 'HE_latency_ave',\n",
    "                                       'active_lever_count', 'active_lever_latency_1st',\n",
    "                                       'inactive_lever_count', 'inactive_lever_latency_1st', \n",
    "                                       'active_lever_latency_ave', 'inactive_lever_latency_ave', 'reinforcement_latency_ave']]\n",
    "\n",
    "lp_train_df_trial['lever_ratio'] = lp_train_df_trial['active_lever_count'] / (lp_train_df_trial['active_lever_count'] + lp_train_df_trial['inactive_lever_count'])\n",
    "\n",
    "print(lp_train_df_trial.shape)\n",
    "lp_train_df_trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_train_df_trial.to_csv('LPD.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = file_paths[7]\n",
    "print('file_path:', '\\n', file_path, '\\n')\n",
    "\n",
    "task, session, animal, date = get_file_info_common(file_path)\n",
    "print('date:', date, 'animal:', animal, 'task:', task, 'session:', session, '\\n')\n",
    "\n",
    "array = make_array_from_path(file_path)\n",
    "print(array[0:50], '\\n')\n",
    "\n",
    "events_and_times = get_events_and_times(array, \"E:\", \"T:\")\n",
    "print(events_and_times.head(), '\\n')\n",
    "\n",
    "trial_times = get_trial_times_LPD(events_and_times, 46,47,12,13,100)\n",
    "print(trial_times.head(), '\\n')\n",
    "\n",
    "trial_data = create_trial_df(events_and_times, trial_times, 'within')\n",
    "print(trial_data.head(), '\\n')\n",
    "\n",
    "ITI_trial_data = create_trial_df(events_and_times, trial_times, 'ITI')\n",
    "print(ITI_trial_data.head(), '\\n')\n",
    "\n",
    "bit_dic = {'reinforcement': 17, 'right_lever': 4, 'left_lever': 3, 'HE_trial': 7}\n",
    "session_data = create_session_df(trial_data, bit_dic, 'within')\n",
    "\n",
    "ITI_dic = {'right_lever': 10, 'left_lever': 11, 'HE_trial': 14}\n",
    "ITI_data = create_session_df(ITI_trial_data, ITI_dic, 'ITI')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
