{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import re\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use os module to create list of data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_2 = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Behavior/Med boxes/Pavlovian/round 2 9.2018/Pav/Pav7'\n",
    "path_1 = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/Behavior/Med boxes/Pavlovian/round 1 6.2018/Pav/Pav7'\n",
    "session_list_1 = os.listdir(path_1)\n",
    "session_list_2 = os.listdir(path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_paths = []\n",
    "for file in session_list_1:\n",
    "    file_path = path_1 + '/' + file\n",
    "    file_paths.append(file_path)\n",
    "    \n",
    "file_paths_2 = []\n",
    "for file in session_list_2:\n",
    "    file_path = path_2 + '/' + file\n",
    "    file_paths.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(file_path_name):\n",
    "    # takes in a file name, finds the date, animal_number, and session and saves each accordingly\n",
    "    import re\n",
    "    \n",
    "    path_split = file_path_name.split('/')\n",
    "    file_split = path_split[-1].split('_')\n",
    "    \n",
    "    for row in file_split:\n",
    "        if re.search(r'^......$', row):\n",
    "            date = row\n",
    "        if re.search(r'^...$', row):\n",
    "            animal_number = row\n",
    "        if re.search(r'^....$', row):\n",
    "            session = row\n",
    "\n",
    "    return date, animal_number, session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_array_from_path (file_path_name):\n",
    "    # takes in path, creates array (each row of array is a row from original med file)\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    data = pd.read_table(file_path_name)\n",
    "    data_table = pd.DataFrame(data = data)\n",
    "    data_array = data_table.values\n",
    "    \n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_and_times(array, event_letter, time_letter):\n",
    "    #takes in array and the letters Med PC program uses to signify an event_stamp and time_stamp; \n",
    "    #finds all event_stamps and corresponding time_stamps; creats pandas dataframe\n",
    "    import re\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    i = 0\n",
    "    event_data = []\n",
    "    time_data = []\n",
    "    while i < len(array):\n",
    "        if re.search(str(event_letter + ':'), str(array[i])):\n",
    "            i = i + 1\n",
    "            while re.search('\\[\\'\\ ', str(array[i])):\n",
    "                split = array[i][0].split()[1:]\n",
    "                for element in split:\n",
    "                    event_data.append(float(element))\n",
    "                i = i + 1\n",
    "        if re.search(str(time_letter + ':'), str(array[i])):\n",
    "            i = i + 1\n",
    "            while re.search('\\[\\'\\ ', str(array[i])):\n",
    "                split = array[i][0].split()[1:]\n",
    "                for element in split:\n",
    "                    time_data.append(float(element))\n",
    "                i = i + 1\n",
    "        i = i + 1\n",
    "    \n",
    "    eandt = np.column_stack((event_data, time_data))\n",
    "    es_et = pd.DataFrame(data = eandt)\n",
    "    es_et.columns = ['event_stamp', 'time_stamp']\n",
    "    \n",
    "    return es_et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_times(events_and_times, trial_start, trial_end, ITI_start, ITI_end):\n",
    "    #takes in dataframe of events and corresponding time_stamps and the Med PC program code for start and end of trial segment\n",
    "    #e.g. conditioned stimulus onset and offset, ITI onset and offset\n",
    "    #finds time_stamps for each start and end, puts into new dataframe\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    start_time = events_and_times[events_and_times.event_stamp == trial_start]['time_stamp'].values\n",
    "    end_time = events_and_times[events_and_times.event_stamp == trial_end]['time_stamp'].values\n",
    "    start_time_ITI = events_and_times[events_and_times.event_stamp == ITI_start]['time_stamp'].values\n",
    "    end_time_ITI = events_and_times[events_and_times.event_stamp == ITI_end]['time_stamp'].values\n",
    "    \n",
    "    times = pd.DataFrame(data = [start_time, end_time, start_time_ITI[0:len(start_time)], end_time_ITI[0:len(start_time)]])\n",
    "    times = times.T\n",
    "    times.columns = ['trial_start', 'trial_end', 'ITI_start', 'ITI_end']\n",
    "    \n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trials_df(events_and_times, trial_times):\n",
    "    \n",
    "    i = 0\n",
    "    trial_data = pd.DataFrame()\n",
    "    \n",
    "    while i < len(trial_times):\n",
    "        data = events_and_times[(events_and_times['time_stamp'] >= trial_times.trial_start[i]) & (events_and_times['time_stamp'] <= trial_times.trial_end[i])]\n",
    "        data['trial_#'] = [i+1]*len(data)\n",
    "        data['trial_start'] = trial_times.trial_start[i]\n",
    "        trial_data = pd.concat([trial_data, data], axis = 0, ignore_index=True)\n",
    "        i = i + 1\n",
    "    \n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(trial_data, bit, trials=25):\n",
    "    i = 0\n",
    "    count = []\n",
    "    while i < trials:\n",
    "        data = trial_data[trial_data['trial_#'] == i]\n",
    "        count.append(len(data[data['event_stamp'] == bit]))\n",
    "        i = i + 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latency(trial_data, bit, trials=25):\n",
    "    i = 0\n",
    "    latency_1st = []\n",
    "    latency_ave = []\n",
    "    while i < trials:\n",
    "        data = trial_data[trial_data['trial_#'] == i]\n",
    "        data = data[data['event_stamp'] == bit]\n",
    "        if len(data) < 1:\n",
    "            latency_1st.append(0.0)\n",
    "            latency_ave.append(0.0)\n",
    "        else:\n",
    "            latency_1st.append((data['time_stamp'] - data['trial_start']).values[0])\n",
    "            latency_ave.append((data['time_stamp'] - data['trial_start']).values.mean())\n",
    "        i = i + 1\n",
    "    \n",
    "    return latency_1st, latency_ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_session_df(trial_data, bit_list, trials = 25):\n",
    "    session_data = pd.DataFrame(index=np.arange(0,trials))\n",
    "    \n",
    "    for bit in bit_list:\n",
    "        session_data[str('count_bit' + str(bit))] = count(trial_data, bit)\n",
    "        session_data[str('latency_1st_bit' + str(bit))], session_data[str('latency_ave_bit' + str(bit))] = latency(trial_data, bit)\n",
    "    \n",
    "    return session_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = file_paths[0]\n",
    "name, animal_number, session = get_file_info(file_path)\n",
    "array = make_array_from_path(file_path)\n",
    "events_and_times = get_events_and_times(array, \"E\", \"T\")\n",
    "trial_times = get_trial_times(events_and_times, 22, 23, 15, 16)\n",
    "trial_data = create_trials_df(events_and_times, trial_times)\n",
    "session_df = create_session_df(trial_data, [6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_analysis(cs_iti, es_et):\n",
    "    #takes in dataframe of cs and ITI start and end times\n",
    "    #takes in dataframe of all event_stamps and corresponding time_stamps\n",
    "    #computes PCA values for each trial and session, places in new dataframe\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    PCA_values = pd.DataFrame()\n",
    "\n",
    "    lever = -1\n",
    "    lever_press = 0 #number of lever press/deflections during cs\n",
    "    head_entries = 0 #number of head entries into the food cup during cs\n",
    "    lever_prob = 0 #number of trials with a lever press, divided by the total number of trials\n",
    "    head_prob = 0 #number of trials with a head entry, divided by the total number of trials\n",
    "    ave_lat_lever = 0 #latency of first lever press averaged over the number of trials with a lever deflection\n",
    "    ave_lat_head = 0 #latency of first head entry averaged over the number of trials with a head entry\n",
    "\n",
    "    count_lever = 0 #running count of trials with a lever press\n",
    "    count_head = 0 #running count of trials with a head entry\n",
    "    lat_lever_sum = 0 #running sum of latency of first lever press for each trial with a lever press\n",
    "    lat_head_sum = 0 #running sum of latency of first head entry for each trial with a head entry\n",
    "\n",
    "    response_bias = 0 #ratio of lever presses and food cup entries in relation to total number of responses\n",
    "    prob_diff = 0 #the difference between the probability of pressing the lever and the probability of entering the food cup\n",
    "    lat_score = 0 #difference between the latencies to approach the lever and the food cup\n",
    "    PCA_score = 0 #ave of above three scores (-1 is completely goal-tracking; +1 is completely sign-tracking)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < 25:\n",
    "        data = es_et[(es_et.time_stamp >= cs_iti.CS_start[i]) & (es_et.time_stamp <= cs_iti.CS_end[i])]\n",
    "\n",
    "        if len(data[data.event_stamp == 1]) > 0:\n",
    "            lever = 1\n",
    "        if len(data[data.event_stamp == 2]) > 0:\n",
    "            lever = 2\n",
    "            \n",
    "        if lever > 0:\n",
    "            lever_press = lever_press + len(data[data.event_stamp == lever])\n",
    "    \n",
    "        head_entries = head_entries + len(data[data.event_stamp == 6])\n",
    "\n",
    "        if len(data[data.event_stamp == lever]) > 0:\n",
    "            count_lever = count_lever + 1\n",
    "            lat_lever = data[data.event_stamp == lever].time_stamp.iloc[0] - cs_iti.CS_start[i]\n",
    "            lat_lever_sum = lat_lever_sum + lat_lever\n",
    "        \n",
    "        if len(data[data.event_stamp == 6]) > 0:\n",
    "            count_head = count_head + 1\n",
    "            lat_head = data[data.event_stamp == 6].time_stamp.iloc[0] - cs_iti.CS_start[i]\n",
    "            lat_head_sum = lat_head_sum + lat_head\n",
    "        \n",
    "        i = i + 1\n",
    "    \n",
    "    lever_prob = count_lever / 25\n",
    "    head_prob = count_head / 25\n",
    "\n",
    "    if lat_lever_sum > 0:\n",
    "        ave_lat_lever = lat_lever_sum / count_lever\n",
    "    if lat_head_sum > 0:\n",
    "        ave_lat_head = lat_head_sum / count_head\n",
    "    \n",
    "    if (lever_press > 0) | (head_entries > 0):\n",
    "        response_bias = (lever_press - head_entries) / (lever_press + head_entries)\n",
    "\n",
    "    prob_diff = lever_prob - head_prob\n",
    "    lat_score = (ave_lat_head - ave_lat_lever) / 10\n",
    "\n",
    "    PCA_score = (response_bias + prob_diff + lat_score) / 3\n",
    "\n",
    "    PCA_values['lever_press'] = [lever_press]\n",
    "    PCA_values['head_entries'] = head_entries\n",
    "    PCA_values['lever_prob'] = lever_prob\n",
    "    PCA_values['head_prob'] = head_prob\n",
    "    PCA_values['ave_lat_lever'] = ave_lat_lever\n",
    "    PCA_values['ave_lat_head'] = ave_lat_head\n",
    "    PCA_values['response_bias'] = response_bias\n",
    "    PCA_values['prob_diff'] = prob_diff\n",
    "    PCA_values['PCA_score'] = PCA_score\n",
    "\n",
    "    return PCA_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_df = PCA_analysis(cs_iti, es_et)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
